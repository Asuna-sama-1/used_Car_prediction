# -*- coding: utf-8 -*-
"""Used_Car_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qqW5EsDyZKyP7eZZVw5rH0HyFI_Jt6L6

Importing libraies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from sklearn import metrics

"""### Load data"""

data = pd.read_csv('Training_DataSet.csv')
data.head(3)

data.duplicated().any()

df = data.copy()
df= df.drop('ListingID',axis=1)

"""## Data Exploration Analysis

any patterns and relationships between variables? 

any missing values? 

any outliers?

#### Variable analysis
"""

df.info()

"""listing price is highly related to 
Engines,features, make, model,mileage seller name, color exi and color int

From the distribution of the price, we can see that the max and mean values are 85k and 32k, which are not that much of difference in terms of car price. Thus, we don't consider any outliers.

### Missing Values
"""

total = df.isnull().sum().sort_values(ascending=False)
percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(20)

df= df[df['VehHistory'].notna()]
df= df[df['VehFeats'].notna()]
df= df[df['VehSellerNotes'].notna()]
df= df[df['Dealer_Listing_Price'].notna()]
df= df[df['Vehicle_Trim'].notna()]

data['VehColorInt'].loc[data['VehColorInt'] == 'Other']

df['VehFuel'] = df.VehFuel.fillna('Unknown')
df['VehColorExt'] = df.VehColorExt.fillna('Other')
df['VehColorInt'] = df.VehColorInt.fillna('Other')
df['VehTransmission'] = df.VehTransmission.fillna('Not Specified')

df['SellerZip'] = df['SellerZip'].fillna(method='ffill')
df['SellerListSrc'] = df['SellerListSrc'].fillna(method='ffill')
df['VehDriveTrain'] = df['VehDriveTrain'].fillna(method='ffill')
df['VehEngine'] = df['VehEngine'].fillna(method='ffill')
df['VehPriceLabel'] = df['VehPriceLabel'].fillna(method='ffill')

df['VehMileage'] = df.VehMileage.fillna(df.VehMileage.mean())
df['Dealer_Listing_Price'] = df.Dealer_Listing_Price.fillna(df.Dealer_Listing_Price.mean())
df['VehListdays'] = df.VehListdays.fillna(df.VehListdays.mean())

"""## Feature Eng

### Continous
"""

df.describe()

df.hist(figsize=(20,12),layout=(2,4))

"""Outliers"""

print('SellerRevCnt above 4k is', len(df[df['SellerRevCnt']>=4000]))
df['SellerRevCnt'] = np.where(df['SellerRevCnt'] >= 4000, df['SellerRevCnt'].mean(), df['SellerRevCnt'])
df.SellerRevCnt.hist()

"""Linear relationship with price"""

sns.set(rc = {'figure.figsize':(30,8)})
fig, ax =plt.subplots(1,5)

sns.regplot(x="VehMileage", y="Dealer_Listing_Price", data=df, ax=ax[0])
sns.regplot(x="VehYear", y="Dealer_Listing_Price", data=df,x_estimator=np.mean, ax=ax[1])
sns.regplot(x="SellerRating", y="Dealer_Listing_Price", data=df, ax=ax[2])
sns.regplot(x="SellerRevCnt", y="Dealer_Listing_Price", data=df, ax=ax[3])
sns.regplot(x="VehListdays", y="Dealer_Listing_Price", data=df, ax=ax[4])

plt.xticks(rotation=45, horizontalalignment='right')
fig.show()

"""### Categorical

Vehicle_Trim
"""

df["Vehicle_Trim"] = df["Vehicle_Trim"].str.lower()
df.Vehicle_Trim.value_counts()

df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('limited', regex=False),'limited')
df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('anniversary', regex=False),'limited')
df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('premium', regex=False),'premium')
df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('altitude', regex=False),'altitude')
df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('srt', regex=False),'srt')
df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('luxury', regex=False),'luxury')
df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('laredo', regex=False),'laredo')
df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('platinum', regex=False),'platinum')
df["Vehicle_Trim"]=df["Vehicle_Trim"].mask(df["Vehicle_Trim"].str.contains('fwd', regex=False),'base')

"""#### SellerIsPriv

when seller is private, there is either veh history nor veh feature data ava

"""

data.SellerIsPriv.value_counts()

data[['SellerCity','SellerName','SellerIsPriv','VehHistory','VehFeats']].loc[data['SellerIsPriv'] == True]

df.SellerIsPriv.describe()

df =df.drop('SellerIsPriv', axis=1)

"""#### VehTransmission

Most shiftable automatics are a regular automatic with electronic override.
"""

df["VehTransmission"] = df["VehTransmission"].str.lower()

df["VehTransmission"]=df["VehTransmission"].mask(df["VehTransmission"].str.contains('a.*t*.*', regex=True),'automatic')
df["VehTransmission"]=df["VehTransmission"].mask(df["VehTransmission"].str.contains('automatic')== False,'not specified')
df["VehTransmission"].value_counts()

plt.figure(figsize = (8,5))
sns.histplot(data=df, x="VehTransmission")

"""#### VehDriveTrain
https://www.vwofalamoheights.com/meaning-of-4x4-4wd-vs-awd-2wd-in-suvs-and-cars/

"""

df["VehDriveTrain"] = df["VehDriveTrain"].str.lower()

# 4WD
df['VehDriveTrain'].mask(df['VehDriveTrain'] == '4x4/4wd', '4wd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == '4x4', '4wd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'four wheel drive', '4wd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == '4x4/4-wheel drive', '4wd', inplace=True)
# FWD
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'front wheel drive', 'fwd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'front-wheel drive', 'fwd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == '2wd', 'fwd', inplace=True)
# AWD
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'all wheel', 'awd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'all wheel drive', 'awd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'all-wheel drive', 'awd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'allwheeldrive', 'awd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'awd or 4x4', 'awd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == '4wd/awd', 'awd', inplace=True)
df['VehDriveTrain'].mask(df['VehDriveTrain'] == 'all-wheel drive with locking and limited-slip differential', 'awd', inplace=True)

plt.figure(figsize = (15,5))
sns.histplot(data=df, x="VehDriveTrain")
plt.xticks(rotation=45)

"""#### SellerListSrc, VehFuel, VehMake, VehModel, VehPriceLabel, VehCertified, VehTransmission,VehDriveTrain"""

sns.set(rc = {'figure.figsize':(25,8)})
fig, ax =plt.subplots(1,5)
sns.countplot(data=df, x='SellerListSrc', ax=ax[4])
sns.countplot(data=df, x='VehFuel',ax=ax[0])
sns.countplot(data=df, x='VehMake', ax=ax[1])
sns.countplot(data=df, x='VehModel',  ax=ax[2])
sns.countplot(data=df, x='VehPriceLabel', ax=ax[3])

plt.xticks(rotation=45, horizontalalignment='right')
fig.show()

sns.set(rc = {'figure.figsize':(12,5)})
fig, ax =plt.subplots(1,3)
sns.countplot(data=df, x='VehCertified', ax=ax[0])
sns.countplot(data=df, x='VehTransmission',ax=ax[1])
sns.countplot(data=df, x='VehDriveTrain',ax=ax[2])

plt.xticks(rotation=45, horizontalalignment='right')
fig.show()

"""drop single value cols """

data.VehBodystyle.describe()

data.VehType.value_counts()

# drop VehBodystyle since it only has one unique value : SUV
df = df.drop('VehBodystyle',axis=1)
df = df.drop('VehType',axis=1)

"""#### VehHistory"""

df.VehHistory.value_counts()

history = df["VehHistory"].str.split(",", n = 1, expand = True)

df['Owners']=history[0].str.split(" ", n = 1, expand = True)[0].astype(int)
df['Accident'] =history[1].str.contains('Accident', regex=False)
df['Non_Personal'] = history[1].str.contains('Non-Personal', regex=False)
df['Buyback_Protection'] = history[1].str.contains('Buyback Protection', regex=False)
df['Title_Issue'] = history[1].str.contains('Title Issue(s)', regex=False)

df['Accident'] = df.Accident.fillna(0)
df['Non_Personal'] = df.Non_Personal.fillna(0)
df['Buyback_Protection'] = df.Buyback_Protection.fillna(0)
df['Title_Issue'] = df.Title_Issue.fillna(0)

df=df.drop('VehHistory', axis=1)

sns.set(rc = {'figure.figsize':(25,8)})
fig, ax =plt.subplots(1,5)
sns.countplot(data=df, x='Owners', ax=ax[0])
sns.countplot(data=df, x='Non_Personal',ax=ax[1])
sns.countplot(data=df, x='Accident',ax=ax[4])
sns.countplot(data=df, x='Buyback_Protection',ax=ax[2])
sns.countplot(data=df, x='Title_Issue',ax=ax[3])

fig.show()

"""#### VehFeats"""

df.VehFeats.describe()

a = df["VehFeats"]

a = a.apply(eval)

df["VehFeats"]

c =[]
for i, l in enumerate(df["VehFeats"]):
  c.append(len(l))
df['fea_count'] = c

# Getting Unique Values or Value Counts
def to_1D(series):
 return pd.Series([x for _list in series for x in _list])

to_1D(a).value_counts()

f = to_1D(a).value_counts().nlargest(20)
f

fig, ax = plt.subplots(figsize = (14,4))
ax.bar(f.index,f.values)
ax.set_ylabel("Frequency", size = 12)
plt.xticks(rotation=45, horizontalalignment='right')

"""#### VehSellerNotes"""

df.VehSellerNotes

"""### Encoding

utilized label encoding to compress the data into integer numbers
"""

df.VehEngine.describe()

from sklearn import preprocessing

le = preprocessing.LabelEncoder()

df['SellerZip'] = le.fit_transform(df.SellerZip)
df['VehEngine'] = le.fit_transform(df.VehEngine)
df['VehColorInt'] = le.fit_transform(df.VehColorInt)
df['SellerState'] = le.fit_transform(df.SellerState)
df['VehColorExt'] = le.fit_transform(df.VehColorExt)
df['SellerListSrc'] = le.fit_transform(df.SellerListSrc)
df['VehDriveTrain'] = le.fit_transform(df.VehDriveTrain)
df['VehFuel'] = le.fit_transform(df.VehFuel)
df['VehMake'] = le.fit_transform(df.VehMake)
df['VehModel'] = le.fit_transform(df.VehModel)
df['VehPriceLabel'] = le.fit_transform(df.VehPriceLabel)
df['VehTransmission'] = le.fit_transform(df.VehTransmission)
df['VehYear'] = le.fit_transform(df.VehYear)

df.replace({False: 0, True: 1}, inplace=True)

df.tail(3)

"""### Feature Selection"""

df_clean = df.copy()
df_clean = df_clean.drop(['SellerCity','SellerName','VehFeats'], axis=1)

all_featurs = df_clean.drop(['Vehicle_Trim','VehSellerNotes'], axis=1)

X =all_featurs.drop('Dealer_Listing_Price', axis=1)
y =df_clean['Dealer_Listing_Price']

from sklearn.feature_selection import mutual_info_classif

importances = mutual_info_classif(X,y)
feat_importances = pd.Series(importances, X.columns[0:len(X.columns)])
feat_importances.plot(kind='barh',color ='teal')
plt.show()

feat_importances.sort_values(ascending=False)

X_selected = X.drop(['VehTransmission','Title_Issue'], axis=1)

from sklearn.feature_selection import f_classif

importances = f_classif(X,y)
feat_importances = pd.Series(importances, X.columns[0:len(X.columns)])
feat_importances.plot(kind='barh',color ='teal')
plt.show()

#Backward Elimination
cols = list(X.columns)
pmax = 1
while (len(cols)>0):
    p= []
    X_1 = X[cols]
    X_1 = sm.add_constant(X_1)
    model = sm.OLS(y,X_1).fit()
    p = pd.Series(model.pvalues.values[1:],index = cols)      
    pmax = max(p)
    feature_with_p_max = p.idxmax()
    if(pmax>0.05):
        cols.remove(feature_with_p_max)
    else:
        break
selected_features_BE = cols
print(selected_features_BE)

len(selected_features_BE)

selected_features_BE

#X=X[['SellerListSrc','SellerState','SellerZip''VehCertified','VehColorInt',
 #'VehDriveTrain','VehEngine','VehMake','VehMileage','VehModel',
 #'VehPriceLabel','VehYear','Owners',
#'Non_Personal']]

"""## Model

### LR
"""

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

trans = MinMaxScaler()
X_scaled = trans.fit_transform(X_selected)

X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size =0.2,random_state=21)

from sklearn.linear_model import LinearRegression

lr=LinearRegression()

lr.fit(X_train,y_train)

print('training data result')
predictions = lr.predict(X_train)

print('mean absolute error is: ',metrics.mean_absolute_error(y_train,predictions))
print('               mape is: ',np.mean(np.abs((y_train - predictions) / y_train))*100)
print(' mean squared error is: ',metrics.mean_squared_error(y_train,predictions))
print('           R2_score is: ',metrics.r2_score(y_train,predictions))
n=X_train.shape[0]
p=X_train.shape[1]
print('  Adjusted R2 score is: ',1-(1-metrics.r2_score(y_train,predictions))*((n-1)/(n-p-1)))


print('testing data result')
predictions = lr.predict(X_test)
print('mean absolute error is: ',metrics.mean_absolute_error(y_test,predictions))
print('               mape is: ',np.mean(np.abs((y_test - predictions) / y_test))*100)
print(' mean squared error is: ',metrics.mean_squared_error(y_test,predictions))
print('           R2_score is: ',metrics.r2_score(y_test,predictions))
n=X_test.shape[0]
p=X_test.shape[1]
print('  Adjusted R2 score is: ',1-(1-metrics.r2_score(y_test,predictions))*((n-1)/(n-p-1)))

"""### RF"""

from sklearn.preprocessing import StandardScaler

X_train,X_test,y_train,y_test=train_test_split(X_selected,y,test_size=0.2,random_state=25)
scaler=MinMaxScaler()

X_train_scaled=scaler.fit_transform(X_train)
X_test_scaled=scaler.transform(X_test)

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)
rf.fit(X_train_scaled, y_train)

print('training data result')
predictions = rf.predict(X_train_scaled)

print('mean absolute error is: ',metrics.mean_absolute_error(y_train,predictions))
print('               mape is: ',np.mean(np.abs((y_train - predictions) / y_train))*100)
print(' mean squared error is: ',metrics.mean_squared_error(y_train,predictions))
print('           R2_score is: ',metrics.r2_score(y_train,predictions))
n=X_test_scaled.shape[0]
p=X_test_scaled.shape[1]
print('  Adjusted R2 score is: ',1-(1-metrics.r2_score(y_train,predictions))*((n-1)/(n-p-1)))

print('testing data result')
predictions = rf.predict(X_test_scaled)

print('mean absolute error is: ',metrics.mean_absolute_error(y_test,predictions))
print('               mape is: ',np.mean(np.abs((y_test - predictions) / y_test))*100)
print(' mean squared error is: ',metrics.mean_squared_error(y_test,predictions))
print('           R2_score is: ',metrics.r2_score(y_test,predictions))
n=X_test_scaled.shape[0]
p=X_test_scaled.shape[1]
print('  Adjusted R2 score is: ',1-(1-metrics.r2_score(y_test,predictions))*((n-1)/(n-p-1)))

"""### XGBoost"""

import xgboost as xgb

X_train,X_test,y_train,y_test=train_test_split(X_selected,y,test_size=0.2,random_state=25)

data_dmatrix = xgb.DMatrix(data=X,label=y)

xg_reg = xgb.XGBRegressor(colsample_bytree = 0.8, learning_rate = 0.1, max_depth = 6, alpha = 12, n_estimators = 200)
xg_reg.fit(X_train,y_train)

print('training data result')
predictions = xg_reg.predict(X_train)

print('mean absolute error is: ',metrics.mean_absolute_error(y_train,predictions))
print('               mape is: ',np.mean(np.abs((y_train - predictions) / y_train))*100)
print(' mean squared error is: ',metrics.mean_squared_error(y_train,predictions))
print('           R2_score is: ',metrics.r2_score(y_train,predictions))
n=X_test_scaled.shape[0]
p=X_test_scaled.shape[1]
print('  Adjusted R2 score is: ',1-(1-metrics.r2_score(y_train,predictions))*((n-1)/(n-p-1)))

print('testing data result')

predictions = xg_reg.predict(X_test)

print('mean absolute error is: ',metrics.mean_absolute_error(y_test,predictions))
print('               mape is: ',np.mean(np.abs((y_test - predictions) / y_test))*100)
print(' mean squared error is: ',metrics.mean_squared_error(y_test,predictions))
print('           R2_score is: ',metrics.r2_score(y_test,predictions))
n=X_test_scaled.shape[0]
p=X_test_scaled.shape[1]
print('  Adjusted R2 score is: ',1-(1-metrics.r2_score(y_test,predictions))*((n-1)/(n-p-1)))

"""## multi label Model"""

all = df_clean.drop(['Dealer_Listing_Price','VehSellerNotes'], axis=1)
X = all.drop('Vehicle_Trim', axis=1)
Y= all.Vehicle_Trim

Y.value_counts()

y = pd.get_dummies(Y, columns=[0])
trim_names = y.columns
trim_names

y.to_numpy()

scaler=MinMaxScaler()
X_scaled=scaler.fit_transform(X)#.toarray()

X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.2,random_state=42)

"""#### RF"""

from skmultilearn.problem_transform import BinaryRelevance
from sklearn.ensemble import RandomForestClassifier

classifier = BinaryRelevance(classifier = RandomForestClassifier(),require_dense = [False, True])
classifier.fit(X_train, y_train)

predictions = classifier.predict(X_test)

br_f1=metrics.f1_score(y_test, predictions, average='micro')
br_hamm=metrics.hamming_loss(y_test,predictions)
print('Binary Relevance F1-score:',round(br_f1,3))
print('Binary Relevance Hamming Loss:',round(br_hamm,3))

"""#### RF- Chain"""

y = y.to_numpy()

from skmultilearn.problem_transform import ClassifierChain

classifier = ClassifierChain(classifier = RandomForestClassifier(),require_dense = [False, True],order=[i for i in range(y.shape[1])])
classifier.fit(X_train,y_train)

predictions = classifier.predict(X_test)

br_f1=metrics.f1_score(y_test, predictions, average='micro')
br_hamm=metrics.hamming_loss(y_test,predictions)
print('Binary Relevance F1-score:',round(br_f1,3))
print('Binary Relevance Hamming Loss:',round(br_hamm,3))

temp = pd.DataFrame(predictions.todense(),columns= trim_names)
new_df = temp.idxmax(axis=1)

"""## Test data """

t_data = pd.read_csv('Test_Dataset.csv')

"""### Pre-processing"""

total = t_data.isnull().sum().sort_values(ascending=False)
percent = (t_data.isnull().sum()/t_data.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(10)

t_data['VehColorInt'] = t_data.VehColorInt.fillna('Other')
t_data['VehDriveTrain'] = t_data['VehDriveTrain'].fillna(method='ffill')
t_data['VehEngine'] = t_data['VehEngine'].fillna(method='ffill')
t_data['VehPriceLabel'] = t_data['VehPriceLabel'].fillna(method='ffill')
t_data['VehColorExt'] = t_data.VehColorExt.fillna('Other')
t_data['VehTransmission'] = t_data.VehTransmission.fillna('Not Specified')
t_data['VehMileage'] = t_data.VehMileage.fillna(t_data.VehMileage.mean())

t_data =t_data.drop(['SellerIsPriv','VehBodystyle','VehType'], axis=1)

t_data["VehTransmission"] = t_data["VehTransmission"].str.lower()
t_data["VehTransmission"]=t_data["VehTransmission"].mask(t_data["VehTransmission"].str.contains('a.*t*.*', regex=True),'automatic')
t_data["VehTransmission"]=t_data["VehTransmission"].mask(t_data["VehTransmission"].str.contains('automatic')== False,'not specified')

t_data["VehDriveTrain"] = t_data["VehDriveTrain"].str.lower()
# 4WD
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == '4x4/4wd', '4wd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == '4x4', '4wd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'four wheel drive', '4wd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == '4x4/4-wheel drive', '4wd', inplace=True)
# FWD
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'front wheel drive', 'fwd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'front-wheel drive', 'fwd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == '2wd', 'fwd', inplace=True)
# AWD
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'all wheel', 'awd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'all wheel drive', 'awd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'all-wheel drive', 'awd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'allwheeldrive', 'awd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'awd or 4x4', 'awd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == '4wd/awd', 'awd', inplace=True)
t_data['VehDriveTrain'].mask(t_data['VehDriveTrain'] == 'all-wheel drive with locking and limited-slip differential', 'awd', inplace=True)


history = t_data["VehHistory"].str.split(",", n = 1, expand = True)

t_data['Owners']=history[0].str.split(" ", n = 1, expand = True)[0]
t_data['Owners'] = t_data.Owners.fillna(method='ffill').astype(int)
t_data['Accident'] =history[1].str.contains('Accident', regex=False)
t_data['Non_Personal'] = history[1].str.contains('Non-Personal', regex=False)
t_data['Buyback_Protection'] = history[1].str.contains('Buyback Protection', regex=False)
t_data['Title_Issue'] = history[1].str.contains('Title Issue(s)', regex=False)
t_data['Accident'] = t_data.Accident.fillna(0)
t_data['Non_Personal'] = t_data.Non_Personal.fillna(0)
t_data['Buyback_Protection'] = t_data.Buyback_Protection.fillna(0)
t_data['Title_Issue'] = t_data.Title_Issue.fillna(0)
t_data=t_data.drop('VehHistory', axis=1)

t_data['VehFeats'] = t_data.VehFeats.fillna(0)

c =[]
#t_data["VehFeats"]=t_data["VehFeats"].apply(eval)
for i, l in enumerate(t_data["VehFeats"]):
  if type(l) == int:
    c.append(0)
  else:
    c.append(len(l))
t_data['fea_count'] = c

t_data['SellerZip'] = le.fit_transform(t_data.SellerZip)
t_data['VehEngine'] = le.fit_transform(t_data.VehEngine)
t_data['VehColorInt'] = le.fit_transform(t_data.VehColorInt)
t_data['SellerState'] = le.fit_transform(t_data.SellerState)
t_data['VehColorExt'] = le.fit_transform(t_data.VehColorExt)
t_data['SellerListSrc'] = le.fit_transform(t_data.SellerListSrc)
t_data['VehDriveTrain'] = le.fit_transform(t_data.VehDriveTrain)
t_data['VehFuel'] = le.fit_transform(t_data.VehFuel)
t_data['VehMake'] = le.fit_transform(t_data.VehMake)
t_data['VehModel'] = le.fit_transform(t_data.VehModel)
t_data['VehPriceLabel'] = le.fit_transform(t_data.VehPriceLabel)
t_data['VehTransmission'] = le.fit_transform(t_data.VehTransmission)
t_data['VehYear'] = le.fit_transform(t_data.VehYear)

t_data.replace({False: 0, True: 1}, inplace=True)

t_data.tail(3)

"""### Prediction"""

t_clean.shape

t_clean = t_data.drop(['SellerCity','SellerName','VehFeats','ListingID','VehSellerNotes'], axis=1)

p1 = xg_reg.predict(t_clean)
p2 = classifier.predict(t_clean)

temp = pd.DataFrame(predictions.todense(),columns= trim_names)

result = pd.DataFrame()
result['ListingID'] = t_data['ListingID']
result['Vehicle_Trim'] = temp.idxmax(axis=1)
result['Dealer_Listing_Pric'] = p1

result.tail(2)

result.to_csv('/content/result.csv')

